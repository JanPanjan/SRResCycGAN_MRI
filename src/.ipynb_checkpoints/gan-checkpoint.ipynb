{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Network with TensorFlow "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T09:52:23.650785Z",
     "start_time": "2025-03-28T09:52:23.647603Z"
    }
   },
   "source": [
    "# for model\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import layers, datasets, Sequential, losses, optimizers\n",
    "import math\n",
    "\n",
    "# for GIFs\n",
    "import glob\n",
    "import imageio\n",
    "import os\n",
    "import sys\n",
    "import PIL\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T09:49:25.369567Z",
     "start_time": "2025-03-28T09:49:25.366471Z"
    }
   },
   "source": [
    "BATCH_SIZE = 64\n",
    "NOISE_DIM = 100\n",
    "IMGS_TO_GEN = 4\n",
    "EPOCHS = 20"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buffer size is primarily used for random sampling using `tf.data.Dataset.shuffle`. Unused for now, Since i will set a seed to make debugging and optimizing easier.\n",
    "\n",
    "Another seed is stored for... idk what."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T09:46:31.637337Z",
     "start_time": "2025-03-28T09:46:31.607978Z"
    }
   },
   "source": [
    "BUFFER_SIZE = 60000\n",
    "tf.random.set_seed(420)\n",
    "seed = tf.random.normal([IMGS_TO_GEN, NOISE_DIM])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 10:46:31.610785: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it is quite natural to add channels other than just red, green, and blue. Many satellite images, in particular for agriculture and meteorology, have tens to hundreds of channels, generating hyperspectral images instead. They report data on many different wavelengths.\n",
    "\n",
    "For now, I will stick to 256 channels (2 to the power of 8) to keep it simple."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T09:46:44.446725Z",
     "start_time": "2025-03-28T09:46:44.442992Z"
    }
   },
   "source": [
    "FEATURE_MAP_SIZE = 7\n",
    "CHANNELS = 256\n",
    "SPATIAL_TENSOR = (FEATURE_MAP_SIZE, FEATURE_MAP_SIZE, CHANNELS)\n",
    "FILTERS = (CHANNELS, 64, 1)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data from keras."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T09:46:47.014878Z",
     "start_time": "2025-03-28T09:46:46.717214Z"
    }
   },
   "source": [
    "(train_imgs, train_lbls), (test_imgs, test_lbls) = datasets.mnist.load_data()"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape img tensor into *(n_instances, px width, px height, channels)*. Channels are the number of color channels in the image. this could be 1 for grayscale or 3 for RGB\n",
    "\n",
    "Since our images are grayscale, set channels to 1 and transform them to float32, since we normalize the data to fall between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T09:49:30.036670Z",
     "start_time": "2025-03-28T09:49:29.762623Z"
    }
   },
   "source": [
    "train_imgs = train_imgs.reshape(train_imgs.shape[0], 28, 28, 1)\n",
    "train_imgs = train_imgs.astype(\"float32\") / 255.0"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a tf dataset and make batches.  Smaller batches hinder training potential, but are less memory intensive.\n",
    "\n",
    "From TensorFlow docs:\n",
    "* for perfect shuffling, a buffer size greater than or equal to the full size of the dataset is required\n",
    "* reshuffle_each_iteration controls whether the shuffle order should be different for each epoch (try without)\n",
    "* To shuffle an entire dataset, set buffer_size=dataset.cardinality(). This is equivalent to setting the buffer_size equal to the number of elements in the dataset, resulting in uniform shuffle."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T09:49:32.132678Z",
     "start_time": "2025-03-28T09:49:31.941017Z"
    }
   },
   "source": [
    "train_df = tf.data.Dataset.from_tensor_slices(train_imgs)\n",
    "\n",
    "# train_df = train_df.batch(BATCH_SIZE).shuffle(BUFFER_SIZE)\n",
    "train_df = train_df.batch(BATCH_SIZE)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 10:49:32.001806: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "### Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with a `Dense` layer that takes an input of 100 random values (noise) and transforms it into a vector of size 7×7×256=12544.\n",
    "\n",
    "`BatchNormalization` helps stabilize training by normalizing the activations of the layer before it.\n",
    "\n",
    "For hidden layers, `LeakyReLU` is better than `ReLU`, since it avoids \"dying ReLU\" problem (sparse gradients). Output layer should have `tanh` activation function, since it our values are normalized to be between -1 and 1, while `sigmoid` outputs values between 0 and 1.\n",
    "\n",
    "`Reshape` transforms 49-element vector into a 7x7x1 tensor, that can be interpreted as a 7px×7px image with 1 channel (one feature map). It converts the vector representation into a spatial representation that can then be processed by convolutional layers.\n",
    "\n",
    "Core of our GAN network: `Conv2DTranspose` does upsampling (it increases the spatial dimensions).  It inserts values into the input and performs a convolution. It adds padding and then applies a standard convolution operation to this expanded output. The kernel weigths are learned during training.\n",
    "\n",
    "While sparse gradients can occur due to ReLU, they also occur as a result of max pooling when doing convolutions. This is why we will use strides. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T09:49:41.507021Z",
     "start_time": "2025-03-28T09:49:41.501120Z"
    }
   },
   "source": [
    "def build_generator():\n",
    "    model = Sequential()\n",
    "    model.add(layers.Input(shape=(100,)))\n",
    "\n",
    "    model.add(layers.Dense(math.prod(SPATIAL_TENSOR), use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape(SPATIAL_TENSOR))\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(FILTERS[0], (5, 5), strides=(1, 1), padding=\"same\", use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(FILTERS[1], (5, 5), strides=(2, 2), padding=\"same\", use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(FILTERS[2], (5, 5), strides=(2, 2), padding=\"same\", activation=\"tanh\", use_bias=False))\n",
    "\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T09:49:45.219249Z",
     "start_time": "2025-03-28T09:49:45.102337Z"
    }
   },
   "source": [
    "generator = build_generator()\n",
    "generator.summary()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m12544\u001B[0m)          │     \u001B[38;5;34m1,254,400\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m12544\u001B[0m)          │        \u001B[38;5;34m50,176\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (\u001B[38;5;33mLeakyReLU\u001B[0m)         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m12544\u001B[0m)          │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (\u001B[38;5;33mReshape\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m256\u001B[0m)      │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m256\u001B[0m)      │     \u001B[38;5;34m1,638,400\u001B[0m │\n",
       "│ (\u001B[38;5;33mConv2DTranspose\u001B[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m256\u001B[0m)      │         \u001B[38;5;34m1,024\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (\u001B[38;5;33mLeakyReLU\u001B[0m)       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m256\u001B[0m)      │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_1              │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │       \u001B[38;5;34m409,600\u001B[0m │\n",
       "│ (\u001B[38;5;33mConv2DTranspose\u001B[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │           \u001B[38;5;34m256\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (\u001B[38;5;33mLeakyReLU\u001B[0m)       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_2              │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m28\u001B[0m, \u001B[38;5;34m28\u001B[0m, \u001B[38;5;34m1\u001B[0m)      │         \u001B[38;5;34m1,600\u001B[0m │\n",
       "│ (\u001B[38;5;33mConv2DTranspose\u001B[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12544</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,254,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12544</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,176</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12544</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,638,400</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">409,600</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,600</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m3,355,456\u001B[0m (12.80 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,355,456</span> (12.80 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m3,329,728\u001B[0m (12.70 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,329,728</span> (12.70 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m25,728\u001B[0m (100.50 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,728</span> (100.50 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discriminator is a convolutional neural network that takes an image as input and outputs a single value, representing the probability that the input is real. In other words, it is a classifier.\n",
    "\n",
    "Input shape is the same as the output shape of the generator. It is 28px×28px image with 1 channel. \n",
    "\n",
    "We gradually go from 28×28 elements to 1 by droping out a third of the neurons every convolution.\n",
    "\n",
    "Lastly, we flatten the remaining neurons into a 1D array that we can pass to the `Dense` output layer with a single output."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T09:49:47.900713Z",
     "start_time": "2025-03-28T09:49:47.896324Z"
    }
   },
   "source": [
    "def build_discriminator():\n",
    "    model = Sequential()\n",
    "    model.add(layers.Input(shape=(28, 28, FILTERS[2])))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T09:49:49.888643Z",
     "start_time": "2025-03-28T09:49:49.821548Z"
    }
   },
   "source": [
    "discriminator = build_discriminator()\n",
    "discriminator.summary()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_1\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001B[38;5;33mConv2D\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │         \u001B[38;5;34m1,664\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_3 (\u001B[38;5;33mLeakyReLU\u001B[0m)       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001B[38;5;33mDropout\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m128\u001B[0m)      │       \u001B[38;5;34m204,928\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_4 (\u001B[38;5;33mLeakyReLU\u001B[0m)       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m128\u001B[0m)      │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m128\u001B[0m)      │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001B[38;5;33mFlatten\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6272\u001B[0m)           │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │         \u001B[38;5;34m6,273\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">204,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6272</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,273</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m212,865\u001B[0m (831.50 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">212,865</span> (831.50 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m212,865\u001B[0m (831.50 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">212,865</span> (831.50 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss\n",
    "\n",
    "It will use cross entropy loss function.\n",
    "`discriminator_loss` will quantify how well the discriminator is able to distinguish real images from fake. It compares its predictions on real images to an array of 1's and fake to an array of 0's.\n",
    "`generator_loss` will quantify how well the generator is able to trick the discriminator. It compares the discriminator's predictions on the generated images to an array of 1's (if its predictions are close to 1, the generator is doing well)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T09:52:09.419973Z",
     "start_time": "2025-03-28T09:52:09.416063Z"
    }
   },
   "source": [
    "cross_entropy = losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss \n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers\n",
    "\n",
    "Since we are training two networks, we need two optimizers."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T09:52:37.540381Z",
     "start_time": "2025-03-28T09:52:37.530274Z"
    }
   },
   "source": [
    "generator_optimizer = optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = optimizers.Adam(1e-4)"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will save checkpoints of the model at regular intervals. This is useful for resuming training at a later time."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T09:53:35.895355Z",
     "start_time": "2025-03-28T09:53:35.891477Z"
    }
   },
   "source": [
    "try:\n",
    "    os.mkdir(\"./training_checkpoints\")\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "checkpoint_dir = \"./training_checkpoints\"\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(\n",
    "    generator_optimizer=generator_optimizer,\n",
    "    discriminator_optimizer=discriminator_optimizer,\n",
    "    generator=generator,\n",
    "    discriminator=discriminator\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "The training loop begins with generator receiving a random seed as input. That seed is \n",
    "used to produce an image. \n",
    "\n",
    "The discriminator is then used to classify real images (drawn from the training set) \n",
    "and fakes images (produced by the generator). \n",
    "\n",
    "The loss is calculated for each of these models, and the gradients are used to update \n",
    "the generator and discriminator."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T09:56:32.832759Z",
     "start_time": "2025-03-28T09:56:32.827787Z"
    }
   },
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    \"\"\"\n",
    "    * generate random noise from a normal distribution using BATCH_SIZE and NOISE_DIM\n",
    "        * generate an image using noise as input\n",
    "        * make 2 predictions with discriminator, one with ground truth images, another\n",
    "        * with the generated image\n",
    "        * compute losses of both models\n",
    "    * compute gradients of both models using their respective loss functions\n",
    "    * apply gradients to both models using their respective optimizers\n",
    "    \"\"\"\n",
    "    noise = tf.random.normal([1, NOISE_DIM])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(\n",
    "       gen_loss, \n",
    "       generator.trainable_variables\n",
    "    )\n",
    "    gradients_of_discriminator = disc_tape.gradient(\n",
    "       disc_loss,\n",
    "       discriminator.trainable_variables\n",
    "    )\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(\n",
    "       gradients_of_generator, \n",
    "       generator.trainable_variables\n",
    "    ))\n",
    "    discriminator_optimizer.apply_gradients(zip(\n",
    "       gradients_of_discriminator, \n",
    "       discriminator.trainable_variables\n",
    "    ))"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T09:56:36.260237Z",
     "start_time": "2025-03-28T09:56:36.255302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    \"\"\"\n",
    "    * Notice `training` is set to False. This is so all layers run in inference mode (batchnorm).\n",
    "      Inference mode means the model is not learning, it is only making predictions\n",
    "    * make predictions using the generator model\n",
    "    * plot the images in a 4x4 grid\n",
    "    * save the plot to a file\n",
    "    \"\"\"\n",
    "    predictions = model(test_input, training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        # here we are scaling the pixel values to be between 0 and 255 with the formula: (x + 1) * 127.5\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T09:56:37.958364Z",
     "start_time": "2025-03-28T09:56:37.953309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(dataset, epochs):\n",
    "    \"\"\"\n",
    "    * for each epoch and for each batch in the dataset we call `train_step` with the\n",
    "      batch and record the time it took to complete the epoch\n",
    "    * clear the output\n",
    "    * generate and save images using the generator model and the seed (noise) we d\n",
    "      defined at the beginning\n",
    "    * save the model every 15 epochs\n",
    "    * print the time it took to complete the epoch\n",
    "    \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        for image_batch in dataset:\n",
    "            train_step(image_batch)\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "        generate_and_save_images(generator, epoch + 1, seed)\n",
    "\n",
    "        if (epoch + 1) % 15 == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "\n",
    "        print(\"Time for epoch {} is {} sec\".format(epoch + 1, time.time() - start))\n",
    "\n",
    "    # Generate after the final epoch\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator, epochs, seed)"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how a random generated image looks like."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T09:56:54.470907Z",
     "start_time": "2025-03-28T09:56:54.391285Z"
    }
   },
   "source": [
    "some_noise = tf.random.normal([1, 100])\n",
    "gen_img = generator(some_noise, training=False)\n",
    "plt.imshow(gen_img[0, :, :, 0], cmap='gray')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T09:56:57.004671Z",
     "start_time": "2025-03-28T09:56:56.993905Z"
    }
   },
   "source": [
    "prediction = discriminator(gen_img, training=False)\n",
    "prediction.numpy().item()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-27.07309341430664"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use `train` function to train our models and see output images."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "train(train_df, EPOCHS)"
   ],
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch 1 is 60.37310075759888 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[48]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_df\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mEPOCHS\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[43]\u001B[39m\u001B[32m, line 15\u001B[39m, in \u001B[36mtrain\u001B[39m\u001B[34m(dataset, epochs)\u001B[39m\n\u001B[32m     12\u001B[39m start = time.time()\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m image_batch \u001B[38;5;129;01min\u001B[39;00m dataset:\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m     \u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     17\u001B[39m display.clear_output(wait=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m     18\u001B[39m generate_and_save_images(generator, epoch + \u001B[32m1\u001B[39m, seed)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/progAAAAAAA/GAN-osuprProject/.venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    148\u001B[39m filtered_tb = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    149\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m150\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    151\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    152\u001B[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/progAAAAAAA/GAN-osuprProject/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001B[39m, in \u001B[36mFunction.__call__\u001B[39m\u001B[34m(self, *args, **kwds)\u001B[39m\n\u001B[32m    830\u001B[39m compiler = \u001B[33m\"\u001B[39m\u001B[33mxla\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mnonXla\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    832\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m._jit_compile):\n\u001B[32m--> \u001B[39m\u001B[32m833\u001B[39m   result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    835\u001B[39m new_tracing_count = \u001B[38;5;28mself\u001B[39m.experimental_get_tracing_count()\n\u001B[32m    836\u001B[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/progAAAAAAA/GAN-osuprProject/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001B[39m, in \u001B[36mFunction._call\u001B[39m\u001B[34m(self, *args, **kwds)\u001B[39m\n\u001B[32m    875\u001B[39m \u001B[38;5;28mself\u001B[39m._lock.release()\n\u001B[32m    876\u001B[39m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[32m    877\u001B[39m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m878\u001B[39m results = \u001B[43mtracing_compilation\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    879\u001B[39m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_variable_creation_config\u001B[49m\n\u001B[32m    880\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    881\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._created_variables:\n\u001B[32m    882\u001B[39m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mCreating variables on a non-first call to a function\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    883\u001B[39m                    \u001B[33m\"\u001B[39m\u001B[33m decorated with tf.function.\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/progAAAAAAA/GAN-osuprProject/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[39m, in \u001B[36mcall_function\u001B[39m\u001B[34m(args, kwargs, tracing_options)\u001B[39m\n\u001B[32m    137\u001B[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001B[32m    138\u001B[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001B[32m--> \u001B[39m\u001B[32m139\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[32m    140\u001B[39m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfunction\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[32m    141\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/progAAAAAAA/GAN-osuprProject/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001B[39m, in \u001B[36mConcreteFunction._call_flat\u001B[39m\u001B[34m(self, tensor_inputs, captured_inputs)\u001B[39m\n\u001B[32m   1318\u001B[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001B[32m   1319\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001B[32m   1320\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[32m   1321\u001B[39m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1322\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_inference_function\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1323\u001B[39m forward_backward = \u001B[38;5;28mself\u001B[39m._select_forward_and_backward_functions(\n\u001B[32m   1324\u001B[39m     args,\n\u001B[32m   1325\u001B[39m     possible_gradient_type,\n\u001B[32m   1326\u001B[39m     executing_eagerly)\n\u001B[32m   1327\u001B[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/progAAAAAAA/GAN-osuprProject/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001B[39m, in \u001B[36mAtomicFunction.call_preflattened\u001B[39m\u001B[34m(self, args)\u001B[39m\n\u001B[32m    214\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core.Tensor]) -> Any:\n\u001B[32m    215\u001B[39m \u001B[38;5;250m  \u001B[39m\u001B[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m216\u001B[39m   flat_outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    217\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.function_type.pack_output(flat_outputs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/progAAAAAAA/GAN-osuprProject/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001B[39m, in \u001B[36mAtomicFunction.call_flat\u001B[39m\u001B[34m(self, *args)\u001B[39m\n\u001B[32m    249\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m record.stop_recording():\n\u001B[32m    250\u001B[39m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._bound_context.executing_eagerly():\n\u001B[32m--> \u001B[39m\u001B[32m251\u001B[39m     outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_bound_context\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    252\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    253\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    254\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfunction_type\u001B[49m\u001B[43m.\u001B[49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    255\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    256\u001B[39m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    257\u001B[39m     outputs = make_call_op_in_graph(\n\u001B[32m    258\u001B[39m         \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    259\u001B[39m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[32m    260\u001B[39m         \u001B[38;5;28mself\u001B[39m._bound_context.function_call_options.as_attrs(),\n\u001B[32m    261\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/progAAAAAAA/GAN-osuprProject/.venv/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1688\u001B[39m, in \u001B[36mContext.call_function\u001B[39m\u001B[34m(self, name, tensor_inputs, num_outputs)\u001B[39m\n\u001B[32m   1686\u001B[39m cancellation_context = cancellation.context()\n\u001B[32m   1687\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1688\u001B[39m   outputs = \u001B[43mexecute\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1689\u001B[39m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mutf-8\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1690\u001B[39m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1691\u001B[39m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1692\u001B[39m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1693\u001B[39m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1694\u001B[39m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1695\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1696\u001B[39m   outputs = execute.execute_with_cancellation(\n\u001B[32m   1697\u001B[39m       name.decode(\u001B[33m\"\u001B[39m\u001B[33mutf-8\u001B[39m\u001B[33m\"\u001B[39m),\n\u001B[32m   1698\u001B[39m       num_outputs=num_outputs,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1702\u001B[39m       cancellation_manager=cancellation_context,\n\u001B[32m   1703\u001B[39m   )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/progAAAAAAA/GAN-osuprProject/.venv/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001B[39m, in \u001B[36mquick_execute\u001B[39m\u001B[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[39m\n\u001B[32m     51\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     52\u001B[39m   ctx.ensure_initialized()\n\u001B[32m---> \u001B[39m\u001B[32m53\u001B[39m   tensors = \u001B[43mpywrap_tfe\u001B[49m\u001B[43m.\u001B[49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     54\u001B[39m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     55\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m core._NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m     56\u001B[39m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
