// bibliography:
// https://github.com/typst/hayagriva/blob/main/docs/file-format.md

#import "@preview/zebraw:0.5.5": *
#show: zebraw
#let cb-lines(body, hdr: none, no-par: false, w: 80%) = {
  if (no-par == false) { par()[] }
  align(
    center,
    box(
      width: w,
      fill: rgb("#F5F5F5"),
      inset: 5pt,
      radius: 2pt,
      zebraw(header: strong(hdr), body),
    ),
  )
  if (no-par == false) { par()[] }
}

#let cb-nolines(body, hdr: none, no-par: false, w: 80%, fs: 9pt, hl-lines: range(1, 1)) = {
  if (no-par == false) { par()[] }
  align(
    center,
    box(
      width: w,
      fill: rgb("#F5F5F5"),
      inset: 5pt,
      radius: 2pt,
      text(
        size: fs,
        zebraw(
          numbering: false,
          header: hdr,
          highlight-lines: hl-lines,
          body,
        ),
      ),
    ),
  )
  if (no-par == false) { par()[] }
}

#let code(body) = {
  box(fill: rgb("#eeeeee"), radius: 2pt, outset: 2pt, body)
}

#let g(body1, body2) = {
  grid(
    columns: 2,
    body1, body2,
  )
}

#let m(ts: 9pt, body) = {
  text(size: ts, body)
}

#set math.equation(numbering: "(1)")
#set page(paper: "a4", margin: (y: 2cm, x: 2.3cm))
#set heading(numbering: "1.", bookmarked: true)
#set terms(tight: true, hanging-indent: 10pt)

#set text(
  lang: "si",
  size: 9pt,
  weight: "light",
  font: "Iosevka NF",
)

#show heading.where(level: 1): h => {
  linebreak()
  align(center, h)
  par()[]
}
#show heading.where(level: 2): h => {
  par()[]
  align(right, h)
  par()[]
}
#show heading.where(level: 3): h => {
  par()[]
  align(left, h)
  par()[]
}
#show link: l => { text(rgb("#4B69C6"), underline(l)) }
#show figure: f => {
  f
  par()[]
}
#show table.cell.where(y: 0): strong

// naslovnica
\ \ \ \
#align(center, text(28pt)[ Super resolucija MRI slik s pomo캜jo generativnih modelov ])
#par()[]
#par()[]
#align(center, text(12pt)[ Osnove strojnega u캜enja in podatkovnega rudarjenja ])
\ \ \ \ \ \ \ \ \ \
\ \ \ \ \ \ \ \ \ \
\ \ \ \ \ \ \ \ \ \
#align(center, text(12pt)[ 2024/25 ])
#align(center, text(12pt)[ Jan Panjan ])
#pagebreak()
#outline(depth: 3)
#pagebreak()

// 코ele tu nastavi 코tevil캜enje strani, da je naslovnica prazna
#set par(justify: true)
#set page(numbering: "1", number-align: center)
#counter(page).update(1)

= Uvod

Uporaba magnetne resonance za slikanje pacientov je izjemnega pomena za diagnozo in sledenju boleznim, ki motijo zdravje pacientov. Podatki o organih, mehkih tkivih in kosteh - ki jih pridobijo z MRI slikanjem - omogo캜ajo zdravnikom, da bolj u캜inkovito ocenijo stopnjo bolezni in posledi캜no primerno prilagodijo na캜in zdravljenja. Pacienti so tako dele쬹i bolj코ega zdravljenja, kar je 코e predvsem pomembno pri raznih kompleksnih boleznih. Z MRI slikanjem - kljub temu da je izjemno orodje - ni enostavno pridobiti kvalitetnih podatkov. K temu pripomore ve캜 razli캜nih faktorjev, tako 캜love코kih kot mehanskih.

== Problemi MRI slik

캛as priprave na slikanje je dolg, saj mora biti naprava kalibrirana na pacienta.
캛as slikanja je dolg, saj potrebuje naprava dovolj 캜asa, da zajame toliko informacij, da jih lahko zdravniki natan캜no ocenijo. Naprava mora narediti mnogo slik (t.i. _slices_) iz razli캜nih smeri. Vse te slike se na koncu zdru쬴jo v smiselno celoto (t.i. _volume_).
Med slikanjem mora biti pacient na miru. Kakr코nokoli premikanje vmesti v slike neza쬰len 코um in razne artefakte. 캛as pridobivanja slike je sorazmeren s kon캜no kvaliteto slik (manj코i 캜as pridobivanja, manj코a lo캜ljivost). Med drugim so MRI slikanja tudi zelo draga za zdravstvene klinike kot posledica oskrbe naprave. Zaradi tega so dol쬹i tudi pacienti pla캜ati ve캜. Tu pripomorejo t.i. _low-field MRI scanners_, ki so cenej코i. To omogo캜a, da je MRI slikanje dostopno vsem, vendar so slike pridobljene s temi napravami, relativno ni쬵e resolucije.

#par()[]

Pri tem problemu lahko pomagajo SR (super resolution) metode, ki so zmo쬹e rekonstruirati slike nizkih lo캜ljivosti (LR, "low resolution") v slike visokih lo캜ljivosti (HR, "high resolution"). Tu so aktualni t.i. GAN ("generative adversarial networks") modeli, ki so z globokim u캜enjem zmo쬹i rekonstruirati slike z visoko natan캜nostjo. Razvitih je bilo ve캜 GAN modelov katerih namen je super resolucija slik, npr. SRGAN, ESRGAN, Real-ESRGAN,... ter tudi SRResCycGAN oziroma _Super Resolution Residual Cycle-consistent GAN_. @sr-with-mri

== O projektu

Za ta projekt sem si zadal implementirati SRResCycGAN model v jeziku Python z uporabo knji쬹ice TensorFlow. Programska koda je dostopna na #link("https://github.com/JanPanjan/SRResCycGAN_MRI")[github] in na #link("https://colab.research.google.com/drive/15Wztc85dwmdJwXp0B03hag4qVt5m_LR1?usp=sharing")[Google Colab]. Model je bil treniran na #link("https://fastmri.med.nyu.edu/")[FastMRI] podatkih, specifi캜no na t.i. _singlecoil_ (2D) slikah kolen.

= Predstavitev podatkov

Zaradi velike koli캜ine podatkov (\~100GB) sem se omejil na podmno쬴co #code[singlecoil_train] in #code[singlecoil_val] podatkov. Imena uporabljenih datotek so vidna #link("https://github.com/JanPanjan/SRResCycGAN_MRI/blob/main/data/uporabljene_datoteke")[tu].

Podatki so shranjeni v #code[h5] datotekah. Vsaka datoteka predstavlja eno MRI slikanje. Na voljo so rekonstruirane slike pod klju캜em #code[reconstruction_rss] in surovi podatki k-prostora pod klju캜em #code[kspace].

*K-prostor* predstavlja MRI sliko v obliki prostorskih frekvenc. Te frekvence so pridobljene preko MR signalov. Signali, ki so v osnovi kompleksna 코tevila, so pretvorjeni v t.i. _image space_ realnih 코tevil s pomo캜jo inverzne Fourierjeve preslikave.

Oblike (uporabljenih) k-prostorskih podatkov se gibljejo od (28, 640, 320), kjer je 28 코tevilo slik, 640x320 pa velikost polja 코tevil, do (50, 640, 640). Oblike rekonstruiranih slik se razlikujejo samo v 코tevilu slik, od 28 do 50 z velikostmi 320x320.

#par()[]

Spodaj je primer podatkov 10. slike shranjene v datoteki #code[file1000001.h5].

#grid(
  columns: 2, [
    #text(size: 7pt,
      figure(
        image("assets/kspace.png", width: 64%),
        caption: "vizualizacija k-prostorskih podatkov"
      )
    )
  ], [
    #text(size: 7pt,
      figure(
        image("assets/reconstructed.png"),
        caption: "rekonstruirana slika pridobljena iz k-prosorskih podatkov"
      )
    )
  ]
)

#align(center)[
  #text(size: 7pt,
    figure(
      image("assets/primerjava.png"),
      caption: "primerjava rekonstruirane (kspace) in o캜i코캜ene slike (reconstruction_rss)"
    )
  )
]

Za u캜enje modela je bila uporabljena mno쬴ca rekonstruiranih slik (#code[reconstruction_rss]) in sicer v obliki *parov (LR, HR)*, torej slike nizke in visoke lo캜ljivosti. LR slike so pridobljene iz HR slik *bikubi캜no interpolacijo* in so velikosti 80x80, HR slike pa 320x320. Oba nabora slik sta shranjena s 3 kanali.

Metoda #code[create_paired_dataset] postopoma na vsaki datoteki pokli캜e metodo #code[h5_generator], ki nalo쬴, transformira in vrne slike kot par. Podatkovna zbirka #code[tf.data.Dataset] je ustvarjena z #code[BATCH_SIZE=8]. Programska koda je v modulu #link("https://github.com/JanPanjan/SRResCycGAN_MRI/blob/main/src/data_loader.py")[data_loader.py].

= Predstavitev GAN strutkure

GAN modeli so v osnovi sestavljeni iz dveh nevronskih mre - generatorja in diskriminatorja - ki med sabo tekmujeta. Cilj *generatorja* je, da se nau캜i porazdelitev podatkov tako, da bo sposoben generirati resni캜ne slike. Ker sam po sebi ne more prepoznati kdaj so njegove slike resni캜ne je tu potreben *diskriminator*. Njegova naloga je, da se nau캜i razlikovati med generiranimi in resni캜nimi slikami.

#par()[]

Z drugimi besedami, cilj generatorja je, da za nek vzorec LR slik ustvari neresni캜ne HR slike, ki bodo prepri캜ale (oz. preslepile) diskriminatorja v to, da jih oceni kot resni캜ne. Ocene diskriminatorja o resni캜nosti slik so potrebne za u캜enje obeh modelov skozi _backpropagation_, kjer bo diskriminator kaznovan ob napa캜nih ocenah slike (npr. neresni캜no oceni kot resni캜no), generator pa ko bodo njegove slike (pravilno) ocenjene kot neresni캜ne.

#align(center, image("assets/arhitektura.png", width: 70%)) @sr-with-mri

== Adversarialna funkcija izgube <advloss>

Standardna funkcija izgube, ki jo uporabljajo GAN modeli je t.i. *adversarialna izguba*. Deluje na _min-max_ principu, saj poisku코a generator vrednosti funkcije 캜imbolj zmanj코ati, diskriminator pa zve캜ati. V sklopu SRResCycGAN modela lahko funkcijo opi코emo z ena캜bo

#par()[]

#let gent = $theta_G$
#let dist = $theta_G$

#m(ts: 10pt)[$
  min_(gent) max_(dist) EE_(x_r) \[ log(D_dist (x_r)) \] + EE_y \[ log(1 - D_dist (G_gent (y))) \]
$]

#par()[]

- #m($x_r$) zaznamuje resni캜no LR sliko in #m[$G_gent (y)$] generirano neresni캜no HR sliko z vhodno LR sliko #m[$y$]. #m[$EE_x_r$] je pri캜akovana vrednost od vseh resni캜nih slik in #m[$D_dist (x_r)$] diskriminatorjeva ocena verjetnosti, da je vhod #m[$x_r$] resni캜en.

- #m[$EE_y$] je pri캜akovana vrednost vseh vhodnih LR slik #m[$y$] in posledi캜no pri캜akovana vrednost od vseh generiranih slik #m[$G_gent (y)$].

- #m[$D_dist (G_gent (y))$] je diskriminatorjeva ocena verjetnosti, da je generirana slika resni캜na.

- #m[$gent$] in #m[$dist$] predstavljata ute쬴 in biase generatorja #m[$G$] in diskriminatorja #m[$D$].

#par()[]

Taka kot je deluje kot funkcija izgube za diskriminatorja, medtem ko generatorja zanima samo ocena diskriminatorja na njegovih neresni캜nih podatkih, zato je levi 캜len med u캜enjem generatorja izpu코캜en. Njegova funkcija izgube je torej

#par()[]

#m(ts: 10pt)[$
  L_G = 1/N sum_(i=1)^N -log (D_dist (G_dist (y_i))
$]

#par()[]

kjer je #m[$N$] 코tevilo LR vzorcev za u캜enje (batch) in #m[$y_i$] vhodna LR slika. Bolj kot je ocena diskriminatorja blizu 1, bolj je vrednost logaritma (ocena verjetnosti) blizu 0.

#align(center, image("assets/negative-log.png", width: 80%))

= SRResCycGAN

Ve캜ino SR GAN metod uporablja parne podatke LR in HR slik, kjer so LR slike pridobljene z bikubi캜no interpolacijo HR slike. To prisili modele v to, da se nau캜ijo izni캜iti rezultat tega procesa, kar pa ne odra쬬 realnega sveta - *v realnem svetu je degradacija odvisna od veliko faktorjev*, ki na razli캜ne na캜ine degradirajo sliko (코um, artefakti zaradi kompresije, zamegljenost zaradi premikanja, napake v le캜ah, itd.). Modeli zato postanejo zelo dobri v obra캜anju bikubi캜ne interpolacije, vendar se ne obnesejo dobro na pravih _umazanih_ slikah, kjer je funkcija degradacije bolj kompleksna.

#par()[]

SRResCycGAN poisku코a re코iti ta problem tako, da se ne u캜i samo super resolucije (LR -> HR), ampak tudi realisti캜no degradacijo (HR -> LR). Zaradi tega je njegova struktura bolj kompleksna - namesto dveh nevronskih mre ima 코tiri, dva generatorja in dva diskriminatorja.

#par()[]

#align(center)[
  #figure(
    image("assets/architecture_structure/SRResCycGAN.png", width: 80%),
    caption: "Struktura SRResCycGAN"
  ) <model-struktura>
] @srrescycgan

#let gh = $G_(H R)$
#let gl = $G_(L R)$
#let dh = $D_(H R)$
#let dl = $D_(L R)$

#par()[]

Par #m[#gh], #m[#dh] (generator in diskriminator za HR slike) skrbi za u캜enje super resolucije, medtem ko par #m[#gl], #m[#dl] (analogno za LR slike) skrbi za u캜enje degradacije. @srrescycgan

== CycleGAN

Struktura je osnovana, med drugimi, na CycleGAN modelu, katerega cilje je, da se nau캜i aproksimirati preslikavo med vhodno in izhodno sliko v primerih, ko pravi pari slik za treniranje niso na voljo (npr. pri #link("https://www.tensorflow.org/tutorials/generative/style_transfer")[_style transfer_] metodah). Preslikavo #[$G$] med domeno degradiranih LR slik #m[$X$] in domeno 캜istih slik visoke resolucije #m[$Y$] zapi코emo kot #m[$G:X arrow Y$]. Aproksimacija mora biti taka, da postane porazdelitev generiranih slik #m[$G(X)$] nerazlo캜ljiva od porazdelitve #m[$Y$]. Ker je preslikava sama po sebi (z uporabo adversarialne izgube) slabo omejena, obstaja neskon캜no mo쬹ih preslikav. V ta namen je zdru쬰na z inverzno preslikavo #m[$F:Y arrow X$].

=== Cikli캜na izguba <cycloss>

Uvedena je tudi nova funkcija izgube, ki se imenuje *cycle (cyclic) consistency loss* oziroma cikli캜na izguba, ki zagotavlja, da je #m[$F(G(X)) approx X$] in obratno. Intuitivno si lahko to predstavljamo kot "prevod stavka iz sloven코캜ine v angle코캜ino mora biti identi캜en prevodu stavka nazaj v sloven코캜ino". Za #m[$forall x in X$] in #m[$forall y in Y$] so avtorji cikel preslikav #m[$x -> G(x) -> F(G(x)) approx x$] poimenovali *forward cycle consistency* ter #m[$y -> F(y) -> G(F(y)) approx y$] *backward cycle consistency*. Cikla skupaj tvorita omenjeno funkcijo izgube:

#par()[]

#text(size: 12pt)[$
  L_("cyc")(G, F) = EE_(x) \[ norm( F(G(x)) - x )_1 \] + EE_y \[ norm( G(F(y)) - y )_1 \]
$]

#par()[]

V sklopu strukture SRResCycGAN (glej @model-struktura) vzame model #m[#gh] za vhod LR sliko in vrne generirano HR sliko, medtem ko #m[#gl] vzame HR sliko in vrne generirano LR sliko. #[#gh] nadzoruje #m[#dh], ki ocenjuje kako resni캜na je vhodna HR slika, #m[#gl] pa #m[#dl], ki ocenjuje kako resni캜na je vhodna LR slika.  @cyclegan

== HR Generator

Struktura generatorja HR slik je prevzeta iz modela SRResCGAN @srrescgan. Njegova struktura je prikazana spodaj. Deluje na principu "pove캜aj -> izbolj코aj", kar pomeni, da v za캜etnem delu pove캜a resolucijo vhodne LR slike na 쬰ljeno lo캜ljivost, skozi vmesni *residual network* (ali ResNet) izpostavi napake v sliki (코um, artefakti, predstavljene kot feature maps), v zadnjem delu pa se te napake od pove캜ane slike odstranijo. Avtorji so poimenovali njegove dele "Encoder -> ResNet -> Decoder".

#align(center)[
  #text(size: 7pt,
    figure(
      image("assets/architecture_structure/G_HR.png", width: 80%),
      caption: "HR generator model"
    )
  )
] @sr-with-mri

=== Encoder

Struktura se za캜ne z *Encoder* delom, kjer prvi #code[Conv2DTranspose] poskrbi, da se vhodna slika velikosti #code[LR_SHAPE] (80, 80, 3) pove캜a na (320, 320, 3). Zadnja 코tevilka predstavlja 코tevilo kanalov slike (RGB slike => 3 kanali). Drugi #code[Conv2D] sloj poskrbi, da se slika preslika v iz _image_ v _feature space_.

Privzeta vrednost za filtre/kanale (#code[FILTERS]) slojev Encoder-ja in Decoder-ja je 64 ter 5 za velikost konvolucijskega jedra (#code[kernel_size]).

#cb-nolines(w: 100%)[
  ```python
  def Generator_HR(input_shape=LR_SHAPE):
    lr_input = layers.Input(shape=input_shape)
    encoder_out = layers.Conv2DTranspose(
        filters=FILTERS,  # 코tevilo kanalov izhoda; rgb slika ima 3, tu jih vrne 64)
        kernel_size=5,    # dimenzije jedra, ki bo procesiral sliko (5x5)
        strides=4,        # premik jedra (4 => 4x upsampling => 320)
        padding="same"    # doda ravno prav ni캜el na robove, da je kon캜na dimenzija odvisna od strides
    )(lr_input)

    # slu쬴 kot vhod in izhod ResNet-a.
    x = layers.Conv2D(filters=FILTERS, kernel_size=5, padding="same")(encoder_out)
  ...
  ```
]

=== Residual Network

ResNet je arhitektura, ki poisku코a re코iti te쬬ve u캜enja globokih nevronskih mre, npr. problem izginjajo캜ih gradientov (vanishing gradients) in manj코anje natan캜nosti pri ve캜jem 코tevilu slojev. To dose쬰 preko t.i. *globokega residualnega u캜enja* - namesto, da bi vsak sloj aproksimiral preslikavo izhoda prej코njega sloja v naslednjega, ResNet u캜i te sloje, da aproksimirajo t.i. *residualno preslikavo*.

캛e je #m[$H(x)$] 쬰lena preslikava, potem to pomeni, da ResNet u캜i svoje sloje, da aproksimirajo preslikavo #m[$F(x) := H(x) - x$], #m[$H(x) = F(x) + x$]. Avtorji so postavili hipotezo, da je *la쬵e optimizirati residualno preslikavo* kot originalno. 캛e bi bila v skrajnem primeru optimalna re코itev identi캜na preslikava (t.j. #m[$H(x) = x$]) naj bi bilo la쬵e potisniti #m[$F(x)$] proti 0, kot pa se nau캜iti identi캜ne preslikave preko zaporednih slojev. V praksi je formulacija #m[$H(x) - x$] realizirana preko t.i. *presko캜nih povezav (skip connections)*. @resnet

#align(center)[
  #text(size: 7pt,
    figure(
      image("assets/architecture_structure/residual.png", width: 50%),
      caption: "Residualni blok"
    )
  ) <residual-block>
]

To preprosto izgleda tako, da shranimo izhod prej코njega sloja v spremenljivko (#m(ts: 10pt)[$x$] na sliki) za poznej코o uporabo.

#cb-nolines(w: 27%)[
  ```python
  ...
  global_skip = encoder_out
  ...
  ```
]

ResNet je sestavljen iz 5 residualnih blokov. Implementirani so z dvema t.i. *pre-activation* konvolucijskema slojema, kar pomeni, da aktivacijski sloj (v tem modelu PReLU) nastopi pred ute쬰nimi sloji. Izkazalo se je, da to izbolj코a proces optimizacije. @preactivation

Za vsakim konvolucijskim slojem v residualnih blokih nastopi 코e normalizacijski sloj, ki prav tako re코uje problem izginjajo캜ih gradientov in prekomerno prileganje na podatke (overfitting) tako da normalizira vrednosti. Namesto standardnega #code[BatchNormalization] (BN) je uporabljen #code[InstanceNormalization] (IN), saj BN izra캜una povpre캜je in varianco celotnega batch-a, kar pomeni, da je normalizacija vsake slike odvisna od vseh. Izkazalo se je, da je to krivo za razne artefakte v generiranih slikah, zato priporo캜ajo uporabo IN, ki normalizira vsak kanal neodvisno in tako ohranja zna캜ilnosti vsake slike. @instance-norm @sr-with-mri

#cb-nolines(w: 100%)[
  ```python
  ...
  for _ in range(5):
      block_skip = x
      x = layers.PReLU(shared_axes=[1, 2])(block_skip)
      x = layers.Conv2D(filters=FILTERS, kernel_size=3, strides=1, padding="same", use_bias=False)(x)
      x = layers.GroupNormalization(groups=-1, axis=-1)(x)  # -1 za InstanceNormalization

      x = layers.PReLU(shared_axes=[1, 2])(x)
      x = layers.Conv2D(filters=FILTERS, kernel_size=3, strides=1, padding="same", use_bias=False)(x)
      x = layers.GroupNormalization(groups=-1, axis=-1)(x)
      x = layers.Add()([block_skip, x])
  ...
  ```
]

=== Decoder

Decoder vzame izhod residualnih blokov in ga po코lje 코e skozi dva konvolucijska sloja. Drugi sloj naj bi bil t.i. _projection layer_ parametriziran s #m(ts: 11pt)[$sigma$]. Zaradi kompleksnosti sem implementacijo tega poljubnega sloja izpustil in uporabil preprost konvolucijski sloj.

#cb-nolines(w: 100%)[
  ```python
  ...
  decoder_out = layers.Conv2D(filters=FILTERS, kernel_size=5, strides=1, padding="same")(x)
  decoder_out = layers.Conv2D(filters=FILTERS, kernel_size=5, strides=1, padding="same")(decoder_out)
  ...
  ```
]

Kon캜na _residualna slika_ je po decoder-ju od코teta od prej코nje LR slike, shranjena kot #code[global_skip]. Zadnji konvolucijski sloj poskrbi, da ima izhodna slika 3 kanale, ReLU pa da so vrednosti omejene na interval (0, 255).

#cb-nolines(w: 100%)[
  ```python
  ...
  subtracted = layers.Subtract()([global_skip, decoder_out])
  model_out = layers.Conv2D(filters=3, kernel_size=3, strides=1, padding="same", use_bias=False)(subtracted)
  model_out = layers.ReLU(max_value=255)(model_out)  # vrednosti spravi na interval [0,255]

  return Model(inputs=lr_input, outputs=model_out, name="G_HR")
  ```
]

== HR Diskriminator

HR Generator je pod nadzorom HR Diskriminatorja, ki ocenjuje kako resni캜ne so vhodne HR slike.

#align(center)[
  #text(size: 7pt,
    figure(
      image("assets/architecture_structure/D_HR.png", width: 80%),
      caption: "HR diskriminator"
    )
  ) <dhr>
] @sr-with-mri

Struktura je posvojena od SRGAN modela. Ima 10 konvolucijskih slojev z izmenjajo캜imi velikostmi konvolucijskega jedra 3 in 4 ter nara코캜ujo캜im 코tevilom filtrov (64 -> 512). Za vsakim konvolucijskim slojem nastopita LeakyReLU in normalizacijski sloj. Ponovno je BN zamenjan z IN.

#cb-nolines(w: 100%)[
  ```python
  def Discriminator_HR(input_shape=HR_SHAPE):
    hr_input = layers.Input(shape=input_shape)
    x = layers.Conv2D(filters=64, kernel_size=3, strides=1, padding="valid")(hr_input)
    x = layers.LeakyReLU()(x)

    KERNEL_SIZE = (4, 3)
    STRIDES = (2, 1)
    FILTERS = (
        64,
        128, 128,
        256, 256,
        512, 512, 512, 512
    )

    for i in range(9):
        kernel_size = KERNEL_SIZE[0] if i % 2 == 0 else KERNEL_SIZE[1]
        strides = STRIDES[0] if i % 2 == 0 else STRIDES[1]

        x = layers.Conv2D(filters=FILTERS[i], kernel_size=kernel_size, strides=strides, padding="valid")(x)
        x = layers.GroupNormalization(groups=-1, axis=-1)(x)
        x = layers.LeakyReLU()(x)

    x = layers.Flatten()(x)
    x = layers.Dense(units=100)(x)
    x = layers.LeakyReLU()(x)
    model_out = layers.Dense(units=1)(x)

    return Model(inputs=hr_input, outputs=model_out, name="D_HR")
  ```
]

Izhod modela je v tem primeru logit vrednost, ki predstavlja preslikane vrednosti verjetnosti iz intervala #m[$\[0,1\]$] na #m[$\(-infinity, infinity\)$].

== LR Generator

LR Generator ima bolj preprosto, "Conv -> ResNet -> Conv", strukturo. Vsi konvolucijski sloji, razen zadnji, uporabljajo 64 filtrov. *Glava* s tremi konvolucijskimi sloji poskrbi za downsampling vhodne HR slike.

#cb-nolines(w: 100%)[
  ```python
  def Generator_LR(input_shape=HR_SHAPE):
    hr_input = layers.Input(shape=input_shape)

    x = layers.Conv2D(filters=FILTERS, kernel_size=7, padding="same")(hr_input)
    x = layers.GroupNormalization(groups=-1, axis=-1)(x)
    x = layers.LeakyReLU(negative_slope=0.2)(x)

    for _ in range(2):  # downsample
        x = layers.Conv2D(filters=FILTERS, kernel_size=3, strides=2, padding="same")(x)
        x = layers.GroupNormalization(groups=-1, axis=-1)(x)
        x = layers.LeakyReLU(negative_slope=0.2)(x)
  ...
  ```
]

Vmesni *ResNet* je implementiran z residualnimi bloki "Conv -> Norm -> LReLU" s presko캜nimi povezavami.

#cb-nolines(w: 100%)[
  ```python
  ...
  for _ in range(6): # ResNet
      block_skip = x
      x = layers.Conv2D(filters=FILTERS, kernel_size=3, padding="same")(x)
      x = layers.GroupNormalization(groups=-1, axis=-1)(x)
      x = layers.LeakyReLU(negative_slope=0.2)(x)

      x = layers.Conv2D(filters=FILTERS, kernel_size=3, padding="same")(x)
      x = layers.GroupNormalization(groups=-1, axis=-1)(x)
      x = layers.Add()([block_skip, x])
      x = layers.LeakyReLU(negative_slope=0.2)(x)
  ...
  ```
]

Zadnji konvolucijski sloj v *repu* poskrbi, da ima izhodna slika 3 kanale in zadnji ReLU sloj, da so vrednosti na intervalu [0,255].

#cb-nolines(w: 100%)[
  ```python
  ...
  for _ in range(2):
      x = layers.Conv2D(filters=FILTERS, kernel_size=3, padding="same")(x)
      x = layers.GroupNormalization(groups=-1, axis=-1)(x)
      x = layers.LeakyReLU(negative_slope=0.2)(x)

  x = layers.Conv2D(filters=3, kernel_size=7, padding="same")(x)
  model_out = layers.ReLU(max_value=255)(x)  # vrednosti spravi na interval [0,255]

  return Model(inputs=hr_input, outputs=model_out, name="G_LR")
  ```
]

== LR Diskriminator

Deluje podobno kot diskriminator v PatchGAN modelu, kjer model ne poisku코a oceniti celotne slike v kosu kot resni캜no, ampak oceni posamezne kose (patches). To dose쬰 tako, da na koncu ne agregira vseh vrednosti v en #code[Flatten -> Dense] sloj, ampak vrne matriko logitov velikosti 20x20. Vsi konvolucijski sloji uporabljajo velikost jedra 5. 맚evilo filtrov se skozi sloje pove캜a iz 64 na 256, na koncu pa se zdru쬴jo v enega. @patch-gan

Prvi #code[Conv2D] sloj zmanj코a vhodno LR sliko iz 80x80 na 40x40 zaradi #code[strides=2]. Drugi sloj ponovno prepolovi dimenziji na pol, zato je matrika logitov oblike 20x20.

Za vsakim konvolucijskim slojem nastopita normalizacijski in aktivacijski sloj, podobno kot pri ostali modelih.

#cb-nolines(w: 100%)[
  ```python
  KERNEL_SIZE = 5
  FILTERS = [64, 128, 256]

  lr_input = layers.Input(shape=input_shape)

  x = layers.Conv2D(filters=FILTERS[0], kernel_size=KERNEL_SIZE, strides=2, padding="same")(lr_input)
  x = layers.GroupNormalization(groups=-1, axis=-1)(x)
  x = layers.LeakyReLU()(x)
  x = layers.Conv2D(filters=FILTERS[1], kernel_size=KERNEL_SIZE, strides=2, padding="same")(x)
  x = layers.GroupNormalization(groups=-1, axis=-1)(x)
  x = layers.LeakyReLU()(x)
  x = layers.Conv2D(filters=FILTERS[2], kernel_size=KERNEL_SIZE, padding="same")(x)
  x = layers.GroupNormalization(groups=-1, axis=-1)(x)
  x = layers.LeakyReLU()(x)

  model_out = layers.Conv2D(filters=1, kernel_size=KERNEL_SIZE, padding="same")(x)

  return Model(inputs=lr_input, outputs=model_out, name="D_LR")
  ```
]

== Funkcije izgube

Da nau캜imo model super resolucije slik, je potrebna uporaba ve캜 razli캜nih funkcij izgube. Ena캜ba, ki se bo skozi u캜enje optimizirala je

#par()[]

#m(ts: 10pt)[$
  L_(#gh) = L_P + L_G + L_(T V) + lambda_("content") dot L_1 + lambda_("cyclic") dot L_(C Y C)
$]

#par()[]

kjer je #m[$L_P$] izguba zaznave (perceptual loss), #m[$L_G$] adversarialna izguba (adversarial loss), #m[$L_(T V)$] izguba popolne variacije (total variation loss), #m[$L_1$] izguba vsebine (content loss) in #m[$L_(C Y C)$] cikli캜na izguba (cyclic loss). Naloga skalarjev #m[$lambda_("content")$] in #m[$lambda_("cyclic")$] je, da doda vsebinski in cikli캜ni izgubi ve캜jo te쬺, kar sili u캜enje generatorja, da postavi ve캜 pozornosti na ti dve izgubi.

=== Izguba zaznave

Fokusira se na "zaznavno podobnost" dveh slik. To dose쬰 tako, da ra캜una razdalje med posameznimi piksli v prostoru zna캜ilnosti (feature space) namesto v prostoru slik (image space). Definirana je kot L2 (evklidska) norma

#m(ts: 11pt)[$
  L_P = 1/N sum_(i=1)^N norm( Phi(accent(x, hat)_r_i) - Phi(x_g_i) )_2^2
$]

med zemljevidoma zna캜ilnosti (feature maps) generirane HR slike #m[$x_g_i$] in njene resni캜ne HR vrednosti #m[$accent(x, hat)_r_i$]. Zemljevida zna캜ilnosti, ozna캜ena z #m[$Phi(I)$], kjer je #m[$I$] vhodna slika, sta pridobljena iz nekega vmesnega konvolucijskega sloja VGG19 klasifikatorja.

=== Izgube popolne variacije

MRI slike so ponavadi podvr쬰ne nizkemu razmerju med 코umom in signalom (signal-to-noise ratio). To vpliva na u캜enje modela, saj obravnava pomanjkljivosti v slikah kot njihove zna캜ilnosti, kar vodi do popa캜enih HR slik. Izguba popolne variacije tako poisku코a zagotoviti, da je 코um med u캜enjem pravilno obravnavan. Definirana je kot

#m[$
  L_(T V) = 1/N sum_(i=1)^N \( norm( gradient_h G(y_i) - gradient_h (accent(x, hat)_r_i) )_1 + norm( gradient_v G(y_i) - gradient_v (accent(x, hat)_r_i) )_1 \)
$]

#par()[]

kjer sta #m[$gradient_h$] in #m[$gradient_v$] vodoravna in navpi캜na gradienta slike. Kot je razvidno na spodnji sliki, lahko z gradienti zaznamo prisotnost 코uma.

#align(center)[
  #text(size: 7pt,
    figure(
      image("assets/gradients.png", width: 55%),
      caption: "(a) originalna slika, (b) navpi캜ni gradienti, (c) vodoravni gradienti"
    )
  )
] @sr-with-mri

=== Izguba vsebine

Preprosto izra캜una povpre캜je razlik med piksli generirane in resni캜ne HR slike. S tem na 코iroko oceni rekonstrukcijo slike. Definirana je kot L1 norma

#m[$
  L_1 = 1/N sum_(i=1)^n norm( G(y_i) - accent(x, hat)_r_i )_1
$]

med generirano HR sliko #m[$G(y_i)$] pridobljena iz vhodne LR slike #m[$y_i$] in resni캜no HR sliko #m[$accent(x, hat)_r_i$].

#par()[]

#link(<advloss>)[Adversarialna] in #link(<cycloss>)[cikli캜na izguba] sta bili opisani prej. Vse funkcije izgube so definirane znotraj slovarja #code[losses_dict] v modulu #link("https://github.com/JanPanjan/SRResCycGAN_MRI/blob/main/src/losses.py")[losses.py]

== U캜enje

Celotni model je definiran v modulu #link("https://github.com/JanPanjan/SRResCycGAN_MRI/blob/main/src/SRResCycGAN.py")[SRResCycGAN.py]. Za u캜enje sta za #m[$lambda_("content")$] in #m[$lambda_("cyclic")$] uporabljeni privzeti vrednosti 5 in 10. Za vse modele je uporabljen poljuben Adam optimizator @sr-with-mri, definiran na slede캜 na캜in:

#cb-nolines(w: 80%)[
  ```python
def adam_opt(lr=1e-4, b1=0.9, b2=0.999, decay_steps=1e4, decay_rate=0.5):
    """ Custom Adam optimizer s padajo캜im learning rate. """
    lr_schedule = ExponentialDecay(
        initial_learning_rate=lr,
        decay_steps=decay_steps,
        decay_rate=decay_rate,
        staircase=True  # da se lr spremeni na vsakih 10k korakov
    )
    return Adam(learning_rate=lr_schedule, beta_1=b1, beta_2=b2, weight_decay=False)
  ```
]

Metoda #code[ExponentialDecay] poskrbi, da se stopnja u캜enja (na za캜etku #m[$1 칑 10^(-4)$]) vsakih 10'000 korakov prepolovi.

Vsak korak u캜enja, model pokli캜e metodo #code[train_step], ki skrbi za izra캜un vrednosti funkcij izgub in gradientov ter posodabljanja ute쬴 ob dani vhodni resni캜ni LR in HR sliki.

= Rezultati

Kljub temu, da je vse potrebno sprogramirano, 쬬l nisem uspel pridobiti rezultatov zaradi konstantnih napak v Kaggle in Google Colab okolju, ko sem poisku코al pognati model z GPU ali TPU pospe코evalniki. Model je mo쬹o pognati na CPU, vendar je, kljub mojem zoo쬬nem izboru podatkov, za 1 epoch predviden 캜as izvajanja pribli쬹o 52 ur (slika spodaj). 游땴

#par()[]

#align(center)[
  #text(size: 7pt,
    figure(
      image("assets/nemorem-verjet.png", width: 90%),
      caption: "Google Colab, CPU runtime, predviden 캜as izvajanja za vseh 3254 korakov je pribli쬹o 52 ur"
    )
  )
]

#pagebreak()
#bibliography("sources.yml")
